{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "\n",
    "from typing import List, Tuple, Union, Optional\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ImageDataset(Dataset):\n",
    "    \" Base class for image datasets providing visualization of (image, label) samples\"\n",
    "\n",
    "    def __init__(self):\n",
    "        logger.info(\"ImageDataset: init\")\n",
    "        super().__init__()\n",
    "\n",
    "    def show_idx(self,\n",
    "            index:int # Index of the (image,label) sample to visualize\n",
    "        ):\n",
    "        \"display image from data point index of a image dataset\"\n",
    "        X, y = self.__getitem__(index)\n",
    "        plt.figure(figsize = (1, 1))\n",
    "        plt.imshow(X.numpy().reshape(28,28),cmap='gray')\n",
    "        plt.title(f\"Label: {int(y)}\")\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def show_grid(\n",
    "            imgs: List[torch.Tensor], # python list of images dim (C,H,W)\n",
    "            save_path=None, # path where image can be saved\n",
    "            dims:Tuple[int,int] = (28,28)\n",
    "        ):\n",
    "        \"display list of mnist-like images (C,H,W)\"\n",
    "        if not isinstance(imgs, list):\n",
    "            imgs = [imgs]\n",
    "        fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "        for i, img in enumerate(imgs):\n",
    "            img = img.detach()\n",
    "            axs[0, i].imshow(img.numpy().reshape(dims[0],dims[1]))\n",
    "            axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "\n",
    "    def show_random(\n",
    "            self,\n",
    "            n:int=3, # number of images to display\n",
    "            dims:Tuple[int,int] = (28,28)\n",
    "        ):\n",
    "        \"display grid of random images\"\n",
    "        indices = torch.randint(0,len(self), (n,))\n",
    "        images = []\n",
    "        for index in indices:\n",
    "            X, y = self.__getitem__(index)\n",
    "            X = X.reshape(dims[0],dims[1])\n",
    "            images.append(X)\n",
    "        self.show_grid(images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| export \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mMNISTDataset\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mImageDataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMNIST digit dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# path where data is saved\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mMNISTDataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMNISTDataset\u001b[39;00m(ImageDataset):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMNIST digit dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      8\u001b[0m         data_dir:\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/image\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# path where data is saved\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# train or test dataset\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m         transform:torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m=\u001b[39m\u001b[43mtransforms\u001b[49m\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     11\u001b[0m                 transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     12\u001b[0m                 transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.1307\u001b[39m,), (\u001b[38;5;241m0.3081\u001b[39m,))\n\u001b[1;32m     13\u001b[0m             ])\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# TODO: add noramlization?\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(0.1307,), (0.3081,))])\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m     ):\n\u001b[1;32m     18\u001b[0m         os\u001b[38;5;241m.\u001b[39mmakedirs(data_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "#| export \n",
    "\n",
    "class MNISTDataset(ImageDataset):\n",
    "    \"MNIST digit dataset\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir:str='../data/image', # path where data is saved\n",
    "        train = True, # train or test dataset\n",
    "        transform:torchvision.transforms.transforms=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "        # TODO: add noramlization?\n",
    "        # torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(0.1307,), (0.3081,))])\n",
    "\n",
    "    ):\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        super().__init__()\n",
    "        logger.info(\"MNISTDataset: init\")\n",
    "\n",
    "        self.ds = MNIST(\n",
    "            data_dir,\n",
    "            train = train,\n",
    "            transform=transform, \n",
    "            download=True\n",
    "        )\n",
    "\n",
    "    def __len__(self) -> int: # length of dataset\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx # index into the dataset\n",
    "                    ) -> tuple[torch.FloatTensor, int]: # Y image data, x digit number\n",
    "        x = self.ds[idx][0]\n",
    "        y = self.ds[idx][1]\n",
    "        return x, y\n",
    "    \n",
    "    def train_dev_split(\n",
    "            self,\n",
    "            ratio:float, # percentage of train/dev split,\n",
    "        ) -> tuple[torchvision.datasets.MNIST, torchvision.datasets.MNIST]: # train and set mnnist datasets\n",
    "\n",
    "        train_set_size = int(len(self.ds) * ratio)\n",
    "        valid_set_size = len(self.ds) - train_set_size\n",
    "\n",
    "        # split the train set into two\n",
    "        train_set, valid_set = data.random_split(self.ds, [train_set_size, valid_set_size])\n",
    "        # TODO: cast to ImageDataset to allow for drawing\n",
    "        # train_set, valid_set = Dataset(train_set),j Dataset(valid_set)\n",
    "        return train_set, valid_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def foo(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
