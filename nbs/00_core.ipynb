{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "from typing import List, Tuple, Union, Optional\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     level=logging.DEBUG,\n",
    "#     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "#     handlers=[\n",
    "#         logging.StreamHandler(sys.stdout)  # Explicitly use stdout\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Create a custom handler that writes to stdout\n",
    "stdout_handler = logging.StreamHandler(sys.stderr)\n",
    "stdout_handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "stdout_handler.setFormatter(formatter)\n",
    "\n",
    "# Get the root logger and add the handler\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.handlers.clear() \n",
    "root_logger.setLevel(logging.DEBUG)\n",
    "root_logger.addHandler(stdout_handler)\n",
    "\n",
    "# Now add handlers to your specific logger\n",
    "logger = logging.getLogger(__name__)\n",
    "root_logger.handlers.clear() \n",
    "logger.addHandler(stdout_handler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORCE_LOG: This is a diagnostic message\n",
      "2024-12-21 12:44:35,174 - __main__ - INFO - This is a diagnostic message\n",
      "2024-12-21 12:44:35,174 - __main__ - INFO - This is a diagnostic message\n",
      "2024-12-21 12:44:35,174 - __main__ - INFO - This is a diagnostic message\n",
      "FORCE_LOG: This is a warning message\n",
      "2024-12-21 12:44:35,176 - __main__ - WARNING - This is a warning message\n",
      "2024-12-21 12:44:35,176 - __main__ - WARNING - This is a warning message\n",
      "2024-12-21 12:44:35,176 - __main__ - WARNING - This is a warning message\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "# Create a diagnostic function that writes to multiple outputs\n",
    "def force_log_output(message, level=logging.INFO):\n",
    "    # Write to a file\n",
    "    log_file = os.path.join(os.getcwd(), 'nbdev_diagnostic_log.txt')\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"{level}: {message}\\n\")\n",
    "    \n",
    "    # Write to stdout\n",
    "    print(f\"FORCE_LOG: {message}\")\n",
    "    \n",
    "    # Use standard logging\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.log(level, message)\n",
    "\n",
    "# Example usage\n",
    "force_log_output(\"This is a diagnostic message\")\n",
    "force_log_output(\"This is a warning message\", logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ImageDataset(Dataset):\n",
    "    \" Base class for image datasets providing visualization of (image, label) samples\"\n",
    "\n",
    "    def __init__(self):\n",
    "        logger.info(\"ImageDataset: init\")\n",
    "        print(\"##### ImageDataset: init\")\n",
    "        super().__init__()\n",
    "\n",
    "    def show_idx(self,\n",
    "            index:int # Index of the (image,label) sample to visualize\n",
    "        ):\n",
    "        \"display image from data point index of a image dataset\"\n",
    "        X, y = self.__getitem__(index)\n",
    "        plt.figure(figsize = (1, 1))\n",
    "        plt.imshow(X.numpy().reshape(28,28),cmap='gray')\n",
    "        plt.title(f\"Label: {int(y)}\")\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def show_grid(\n",
    "            imgs: List[torch.Tensor], # python list of images dim (C,H,W)\n",
    "            save_path=None, # path where image can be saved\n",
    "            dims:Tuple[int,int] = (28,28)\n",
    "        ):\n",
    "        \"display list of mnist-like images (C,H,W)\"\n",
    "        if not isinstance(imgs, list):\n",
    "            imgs = [imgs]\n",
    "        fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "        for i, img in enumerate(imgs):\n",
    "            img = img.detach()\n",
    "            axs[0, i].imshow(img.numpy().reshape(dims[0],dims[1]))\n",
    "            axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "\n",
    "    def show_random(\n",
    "            self,\n",
    "            n:int=3, # number of images to display\n",
    "            dims:Tuple[int,int] = (28,28)\n",
    "        ):\n",
    "        \"display grid of random images\"\n",
    "        indices = torch.randint(0,len(self), (n,))\n",
    "        images = []\n",
    "        for index in indices:\n",
    "            X, y = self.__getitem__(index)\n",
    "            X = X.reshape(dims[0],dims[1])\n",
    "            images.append(X)\n",
    "        self.show_grid(images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class MNISTDataset(ImageDataset):\n",
    "    \"MNIST digit dataset\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir:str='../data/image', # path where data is saved\n",
    "        train:bool = True, # train or test dataset\n",
    "        transform:torchvision.transforms.transforms=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "        # TODO: add noramlization?\n",
    "        # torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(0.1307,), (0.3081,))])\n",
    "\n",
    "    ):\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        super().__init__()\n",
    "        logger.info(\"MNISTDataset: init\")\n",
    "        try:\n",
    "            self.ds = MNIST(\n",
    "                data_dir,\n",
    "                train = train,\n",
    "                transform=transform, \n",
    "                download=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading MNIST dataset: {e}\")\n",
    "\n",
    "\n",
    "    def __len__(self) -> int: # length of dataset\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx # index into the dataset\n",
    "                    ) -> tuple[torch.FloatTensor, int]: # Y image data, x digit number\n",
    "        x = self.ds[idx][0]\n",
    "        y = self.ds[idx][1]\n",
    "        return x, y\n",
    "    \n",
    "    def train_dev_split(\n",
    "            self,\n",
    "            ratio:float, # percentage of train/dev split,\n",
    "        ) -> tuple[torchvision.datasets.MNIST, torchvision.datasets.MNIST]: # train and set mnnist datasets\n",
    "\n",
    "        train_set_size = int(len(self.ds) * ratio)\n",
    "        valid_set_size = len(self.ds) - train_set_size\n",
    "\n",
    "        # split the train set into two\n",
    "        train_set, valid_set = data.random_split(self.ds, [train_set_size, valid_set_size])\n",
    "        # TODO: cast to ImageDataset to allow for drawing\n",
    "        # train_set, valid_set = Dataset(train_set),j Dataset(valid_set)\n",
    "        return train_set, valid_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-21 12:30:05,873 - __main__ - INFO - ImageDataset: init\n",
      "##### ImageDataset: init\n",
      "2024-12-21 12:30:05,874 - __main__ - INFO - MNISTDataset: init\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"test stuff\")\n",
    "test = MNISTDataset(data_dir='/tmp/new', train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MNIST(\"/tmp/new2\", train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def foo(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
